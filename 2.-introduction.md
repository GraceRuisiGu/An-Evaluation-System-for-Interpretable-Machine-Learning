---
description: Introduction to Evaluation Systems
---

# 2. Introduction

Introduce:

* What does Model Interpretability mean?
* Why do we need Evaluation Systems?
* What are Interpretable models?
* What is Evaluations System?

## 2.1 What does Model Interpretability mean?

There is no mathematical definition of interpretability. 

A \(non-mathematical\) definition is: **Interpretability is the degree to which a human can understand the cause of a decision.** 

Another one is: **Interpretability is the degree to which a human can consistently predict the model's result**. 

The higher the interpretability of a machine learning model, the easier it is for someone to comprehend why certain decisions or predictions have been made. A model is better interpretable than another model if its decisions are easier for a human to comprehend than decisions from the other model.

