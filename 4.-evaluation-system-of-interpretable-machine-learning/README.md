# 4. Evaluation System of Interpretable Machine Learning

Once we have the interpretable models, the next thing we need to do is evaluate the models. As long as we have a metric to assess the interpretable models, we know what makes a good interpretable model looks like, and how to achieve that. A comprehensive evaluation system also helps a user to understand the reliability in the interpretable models.

![](https://lh6.googleusercontent.com/5tBRJeFRD3TZWJ4E0ct0bkb02fNf2NZ8AfHUEEndYu5JmE8b93u8y7HHp9fH4Si-4Gn9UKj9f5BJE6dQVZahRtTeD-VFf_lSUj4nr14gD1tyzitoY2g2YLSU_9fAyL8XXeimX3rS7DQ)

