# 4. Evaluation System of Interpretable Machine Learning

Once we have the interpretable models, we need to judge the interpretability by evaluating the same, to support if the interpretability was trust worthy to proceed ahead with it. This helps a user to understand the reliability in the interpretable models.

![](https://lh6.googleusercontent.com/5tBRJeFRD3TZWJ4E0ct0bkb02fNf2NZ8AfHUEEndYu5JmE8b93u8y7HHp9fH4Si-4Gn9UKj9f5BJE6dQVZahRtTeD-VFf_lSUj4nr14gD1tyzitoY2g2YLSU_9fAyL8XXeimX3rS7DQ)

