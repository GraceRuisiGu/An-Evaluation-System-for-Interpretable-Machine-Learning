# 3. Interpretable Machine Learning

The easiest way to achieve interpretability is to use only a subset of algorithms that create interpretable models. Linear regression, logistic regression, and the decision tree are commonly used, interpretable models.

In the following chapters, we will talk about these models. Not in detail, only the basics, because there is already a ton of books, videos, tutorials, papers, and more material available. We will focus on how to interpret the models. The book discusses [linear regression](https://christophm.github.io/interpretable-ml-book/limo.html#limo), [logistic regression](https://christophm.github.io/interpretable-ml-book/logistic.html#logistic), [other linear regression extensions](https://christophm.github.io/interpretable-ml-book/extend-lm.html#extend-lm), [decision trees](https://christophm.github.io/interpretable-ml-book/tree.html#tree), [decision rules](https://christophm.github.io/interpretable-ml-book/rules.html#rules), and [the RuleFit algorithm](https://christophm.github.io/interpretable-ml-book/rulefit.html#rulefit) in more detail. It also lists [other interpretable models](https://christophm.github.io/interpretable-ml-book/other-interpretable.html#other-interpretable).

